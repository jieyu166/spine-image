#!/usr/bin/env python3
"""
è„Šæ¤Žæ¤Žé«”é ‚é»žæª¢æ¸¬ - æ©Ÿå™¨å­¸ç¿’è¨“ç·´è…³æœ¬ V2.1
Spine Vertebra Corner Detection - ML Training Script V2.1

æ”¯æ´:
- å®Œæ•´æ¤Žé«”: 4 å€‹è§’é»ž
- é‚Šç•Œæ¤Žé«” (S1/T1=ä¸Šçµ‚æ¿ 2é»ž, T12/C2=ä¸‹çµ‚æ¿ 2é»ž)

å¾žè§’é»žè‡ªå‹•è¨ˆç®—ï¼šå£“è¿«æ€§éª¨æŠ˜ã€æ¤Žé–“ç›¤é«˜åº¦ã€æ»‘è„«

æ—¥æœŸ: 2025-2026
"""

import os
import json
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms, models
import pydicom
import cv2
from PIL import Image
import matplotlib.pyplot as plt
from tqdm import tqdm
import albumentations as A
from albumentations.pytorch import ToTensorV2
import warnings
warnings.filterwarnings('ignore')


class VertebraDataset(Dataset):
    """æ¤Žé«”é ‚é»žæª¢æ¸¬æ•¸æ“šé›† V2.1

    æ”¯æ´:
    - å®Œæ•´æ¤Žé«”: 4 è§’é»ž (anteriorSuperior, posteriorSuperior, posteriorInferior, anteriorInferior)
    - ä¸Šé‚Šç•Œæ¤Žé«” (S1/T1): 2 é»ž (anteriorSuperior, posteriorSuperior)
    - ä¸‹é‚Šç•Œæ¤Žé«” (T12/C2): 2 é»ž (posteriorInferior, anteriorInferior)

    ç‚ºçµ±ä¸€æ¨¡åž‹è¼¸å…¥ï¼Œæ¯å€‹æ¤Žé«”å›ºå®š 4 å€‹ slot:
    - å®Œæ•´æ¤Žé«”: 4 å€‹æœ‰æ•ˆé»ž
    - é‚Šç•Œæ¤Žé«”: 2 å€‹æœ‰æ•ˆé»ž + 2 å€‹é›¶å¡«å…… (valid_mask=0)
    """

    # é‚Šç•Œæ¤Žé«”å®šç¾©
    BOUNDARY_CONFIG = {
        'L': {'upper': ['S1'], 'lower': ['T12']},
        'C': {'upper': ['T1'], 'lower': ['C2']},
    }

    def __init__(self, data_dir, annotations_file, transform=None, max_vertebrae=8):
        self.data_dir = data_dir
        self.transform = transform
        self.max_vertebrae = max_vertebrae  # T12-S1 = 8, C2-T1 = 8

        # è¼‰å…¥æ¨™è¨»æ•¸æ“š
        with open(annotations_file, 'r', encoding='utf-8') as f:
            self.annotations = json.load(f)

        if isinstance(self.annotations, dict):
            self.annotations = [self.annotations]

        print(f"è¼‰å…¥ {len(self.annotations)} å€‹æ¨£æœ¬")

    def __len__(self):
        return len(self.annotations)

    def _get_boundary_type(self, name, spine_type, vertebra_data):
        """åˆ¤æ–·æ˜¯å¦ç‚ºé‚Šç•Œæ¤Žé«”

        V2.1: ä½¿ç”¨ boundaryType æ¬„ä½
        V2.0: S1 ç­‰é‚Šç•Œæ¤Žé«”å¯èƒ½æœ‰å®Œæ•´ 4 é»ž â†’ è¦–ç‚ºå®Œæ•´æ¤Žé«”
        """
        # V2.1 æ˜Žç¢ºæ¨™è¨˜
        bt = vertebra_data.get('boundaryType', None)
        if bt:
            return bt

        # V2.0 ç›¸å®¹ï¼šå¦‚æžœæœ‰å®Œæ•´ 4 é»žå°±ç•¶å®Œæ•´æ¤Žé«”
        points = vertebra_data.get('points', {})
        if isinstance(points, dict):
            has_all_4 = all(k in points for k in
                ['anteriorSuperior', 'posteriorSuperior', 'posteriorInferior', 'anteriorInferior'])
            if has_all_4:
                return None
        elif isinstance(points, list) and len(points) >= 4:
            return None

        config = self.BOUNDARY_CONFIG.get(spine_type, {})
        if name in config.get('upper', []):
            return 'upper'
        if name in config.get('lower', []):
            return 'lower'
        return None

    def __getitem__(self, idx):
        annotation = self.annotations[idx]

        # è¼‰å…¥åœ–åƒ
        image = self.load_image(annotation)

        if image is None:
            raise FileNotFoundError(f"Cannot load image for annotation {idx}")

        original_h, original_w = image.shape[:2]
        spine_type = annotation.get('spine_type', annotation.get('spineType', 'L'))

        # æå–æ¤Žé«”é ‚é»ž
        vertebrae = annotation.get('vertebrae', [])
        keypoints = []  # æ‰€æœ‰è§’é»žåº§æ¨™ (æ¯æ¤Žé«”å›ºå®š 4 slot)
        valid_flags = []  # æ¯å€‹ slot æ˜¯å¦æœ‰æ•ˆ
        vertebra_names = []

        for v in vertebrae[:self.max_vertebrae]:
            points = v.get('points', {})
            name = v.get('name', '')
            vertebra_names.append(name)
            boundary = self._get_boundary_type(name, spine_type, v)

            # æ¯å€‹æ¤Žé«”å›ºå®š 4 slots: [anteriorSuperior, posteriorSuperior, posteriorInferior, anteriorInferior]
            if isinstance(points, dict):
                if boundary == 'upper':
                    # ä¸Šé‚Šç•Œ (S1/T1): åªæœ‰ anteriorSuperior + posteriorSuperior
                    corners = [
                        points.get('anteriorSuperior', {}),
                        points.get('posteriorSuperior', {}),
                        None,  # posteriorInferior ä¸å­˜åœ¨
                        None,  # anteriorInferior ä¸å­˜åœ¨
                    ]
                elif boundary == 'lower':
                    # ä¸‹é‚Šç•Œ (T12/C2): åªæœ‰ posteriorInferior + anteriorInferior
                    corners = [
                        None,  # anteriorSuperior ä¸å­˜åœ¨
                        None,  # posteriorSuperior ä¸å­˜åœ¨
                        points.get('posteriorInferior', {}),
                        points.get('anteriorInferior', {}),
                    ]
                else:
                    # å®Œæ•´æ¤Žé«”
                    corners = [
                        points.get('anteriorSuperior', {}),
                        points.get('posteriorSuperior', {}),
                        points.get('posteriorInferior', {}),
                        points.get('anteriorInferior', {}),
                    ]
            else:
                # list æ ¼å¼
                if boundary == 'upper' and len(points) == 2:
                    corners = [points[0], points[1], None, None]
                elif boundary == 'lower' and len(points) == 2:
                    corners = [None, None, points[0], points[1]]
                else:
                    corners = (points[:4] + [None]*4)[:4]

            for corner in corners:
                if corner is not None and corner:
                    x = corner.get('x', 0) if isinstance(corner, dict) else corner[0]
                    y = corner.get('y', 0) if isinstance(corner, dict) else corner[1]
                    keypoints.append([x, y])
                    valid_flags.append(1.0)
                else:
                    keypoints.append([0.0, 0.0])
                    valid_flags.append(0.0)

        # æ‡‰ç”¨è®Šæ› - åªå°æœ‰æ•ˆ keypoints åšè®Šæ›
        valid_kp_indices = [i for i, f in enumerate(valid_flags) if f > 0]
        valid_kp = [keypoints[i] for i in valid_kp_indices]

        if self.transform and len(valid_kp) > 0:
            transformed = self.transform(image=image, keypoints=valid_kp)
            image = transformed['image']
            transformed_valid_kp = transformed['keypoints']

            # é‡å»ºå®Œæ•´ keypoints åˆ—è¡¨
            transformed_kp = [[0.0, 0.0]] * len(keypoints)
            for j, idx_orig in enumerate(valid_kp_indices):
                transformed_kp[idx_orig] = list(transformed_valid_kp[j])
        else:
            # åŸºæœ¬è®Šæ›
            image = cv2.resize(image, (512, 512))
            scale_x = 512 / original_w
            scale_y = 512 / original_h
            transformed_kp = []
            for i, kp in enumerate(keypoints):
                if valid_flags[i] > 0:
                    transformed_kp.append([kp[0] * scale_x, kp[1] * scale_y])
                else:
                    transformed_kp.append([0.0, 0.0])
            image = torch.from_numpy(image).permute(2, 0, 1).float() / 255.0

        # æ­£è¦åŒ–é—œéµé»žåˆ° [0, 1]
        h, w = 512, 512
        normalized_kp = []
        for i, kp in enumerate(transformed_kp):
            if valid_flags[i] > 0:
                normalized_kp.append([kp[0] / w, kp[1] / h])
            else:
                normalized_kp.append([0.0, 0.0])

        # å¡«å……åˆ°å›ºå®šé•·åº¦ (max_vertebrae * 4 å€‹é»ž)
        max_points = self.max_vertebrae * 4
        while len(normalized_kp) < max_points:
            normalized_kp.append([0.0, 0.0])
        while len(valid_flags) < max_points:
            valid_flags.append(0.0)

        # å‰µå»ºç†±åœ–ç›®æ¨™ (åªç”¨æœ‰æ•ˆçš„ keypoints)
        valid_transformed_kp = [transformed_kp[i] for i in valid_kp_indices]
        heatmap = self.create_heatmap(valid_transformed_kp, (h, w))

        targets = {
            'keypoints': torch.tensor(normalized_kp[:max_points], dtype=torch.float32),  # [N*4, 2]
            'valid_mask': torch.tensor(valid_flags[:max_points], dtype=torch.float32),  # [N*4]
            'heatmap': torch.tensor(heatmap, dtype=torch.float32).unsqueeze(0),  # [1, H, W]
            'num_vertebrae': len(vertebrae),
            'vertebra_names': vertebra_names
        }

        return image, targets

    def load_image(self, annotation):
        """è¼‰å…¥åœ–åƒ"""
        image_path = annotation.get('image_path', '')
        full_path = os.path.join(self.data_dir, image_path)

        if os.path.exists(full_path):
            if full_path.lower().endswith('.dcm'):
                try:
                    dcm = pydicom.dcmread(full_path)
                    image = dcm.pixel_array
                    if len(image.shape) == 2:
                        image = np.stack([image] * 3, axis=-1)
                    image = ((image - image.min()) / (image.max() - image.min() + 1e-8) * 255).astype(np.uint8)
                    return image
                except Exception as e:
                    print(f"Error loading DICOM {full_path}: {e}")
            else:
                image = cv2.imread(full_path)
                if image is not None:
                    return cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

        # æœå°‹åŒåæª”æ¡ˆ
        source_file = annotation.get('source_file', '')
        if source_file:
            base_name = os.path.splitext(source_file)[0]
            for ext in ['.dcm', '.png', '.jpg']:
                candidate = os.path.join(self.data_dir, base_name + ext)
                if os.path.exists(candidate):
                    return self.load_image({'image_path': base_name + ext})

        return None

    def create_heatmap(self, keypoints, size, sigma=5):
        """å‰µå»ºé«˜æ–¯ç†±åœ–"""
        h, w = size
        heatmap = np.zeros((h, w), dtype=np.float32)

        for kp in keypoints:
            x, y = int(kp[0]), int(kp[1])
            if 0 <= x < w and 0 <= y < h:
                # å‰µå»ºé«˜æ–¯é»ž
                for dy in range(-sigma*2, sigma*2+1):
                    for dx in range(-sigma*2, sigma*2+1):
                        ny, nx = y + dy, x + dx
                        if 0 <= ny < h and 0 <= nx < w:
                            dist = (dx*dx + dy*dy) / (2 * sigma * sigma)
                            heatmap[ny, nx] = max(heatmap[ny, nx], np.exp(-dist))

        return heatmap


class VertebraCornerModel(nn.Module):
    """æ¤Žé«”é ‚é»žæª¢æ¸¬æ¨¡åž‹

    æŽ¡ç”¨é›™åˆ†æ”¯æž¶æ§‹:
    1. ç†±åœ–åˆ†æ”¯: é æ¸¬è§’é»žä½ç½®çš„ç†±åœ– (ç”¨æ–¼ç²—å®šä½)
    2. å›žæ­¸åˆ†æ”¯: ç›´æŽ¥å›žæ­¸è§’é»žåº§æ¨™ (ç”¨æ–¼ç²¾ç¢ºå®šä½)
    """

    def __init__(self, max_vertebrae=8, pretrained=True):
        super(VertebraCornerModel, self).__init__()

        self.max_vertebrae = max_vertebrae
        self.num_points = max_vertebrae * 4  # æ¯å€‹æ¤Žé«”4å€‹ slot (é‚Šç•Œæ¤Žé«”2æœ‰æ•ˆ+2å¡«å……)

        # Backbone - ResNet50
        resnet = models.resnet50(pretrained=pretrained)
        self.backbone = nn.Sequential(*list(resnet.children())[:-2])  # ç§»é™¤FCå’ŒAvgPool

        # ç†±åœ–åˆ†æ”¯ (Heatmap Branch) - ç”¨æ–¼ç²—å®šä½
        self.heatmap_branch = nn.Sequential(
            nn.Conv2d(2048, 512, 3, padding=1),
            nn.BatchNorm2d(512),
            nn.ReLU(inplace=True),
            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True),
            nn.Conv2d(512, 256, 3, padding=1),
            nn.BatchNorm2d(256),
            nn.ReLU(inplace=True),
            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True),
            nn.Conv2d(256, 128, 3, padding=1),
            nn.BatchNorm2d(128),
            nn.ReLU(inplace=True),
            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True),
            nn.Conv2d(128, 64, 3, padding=1),
            nn.BatchNorm2d(64),
            nn.ReLU(inplace=True),
            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True),
            nn.Conv2d(64, 1, 1),  # è¼¸å‡ºç†±åœ–
            nn.Sigmoid()
        )

        # å›žæ­¸åˆ†æ”¯ (Regression Branch) - ç›´æŽ¥é æ¸¬åº§æ¨™
        self.regression_branch = nn.Sequential(
            nn.AdaptiveAvgPool2d(1),
            nn.Flatten(),
            nn.Linear(2048, 1024),
            nn.ReLU(inplace=True),
            nn.Dropout(0.3),
            nn.Linear(1024, 512),
            nn.ReLU(inplace=True),
            nn.Dropout(0.3),
            nn.Linear(512, self.num_points * 2),  # è¼¸å‡º [N*4, 2] åº§æ¨™
            nn.Sigmoid()  # æ­£è¦åŒ–åˆ° [0, 1]
        )

        # æ¤Žé«”æ•¸é‡é æ¸¬ (è¼”åŠ©ä»»å‹™)
        self.count_head = nn.Sequential(
            nn.AdaptiveAvgPool2d(1),
            nn.Flatten(),
            nn.Linear(2048, 256),
            nn.ReLU(inplace=True),
            nn.Linear(256, max_vertebrae + 1)  # 0 åˆ° max_vertebrae
        )

    def forward(self, x):
        # Backbone features
        features = self.backbone(x)  # [B, 2048, H/32, W/32]

        # ç†±åœ–é æ¸¬
        heatmap = self.heatmap_branch(features)  # [B, 1, H/2, W/2]

        # åº§æ¨™å›žæ­¸
        coords = self.regression_branch(features)  # [B, N*4*2]
        coords = coords.view(-1, self.num_points, 2)  # [B, N*4, 2]

        # æ¤Žé«”æ•¸é‡é æ¸¬
        count_logits = self.count_head(features)  # [B, max_vertebrae+1]

        return {
            'heatmap': heatmap,
            'coords': coords,
            'count_logits': count_logits
        }


class VertebraLoss(nn.Module):
    """æ¤Žé«”é ‚é»žæª¢æ¸¬æå¤±å‡½æ•¸"""

    def __init__(self, alpha=1.0, beta=2.0, gamma=0.5):
        super(VertebraLoss, self).__init__()
        self.alpha = alpha  # ç†±åœ–æå¤±æ¬Šé‡
        self.beta = beta    # åº§æ¨™å›žæ­¸æå¤±æ¬Šé‡
        self.gamma = gamma  # è¨ˆæ•¸æå¤±æ¬Šé‡

        self.mse = nn.MSELoss(reduction='none')
        self.bce = nn.BCELoss()
        self.ce = nn.CrossEntropyLoss()

    def forward(self, predictions, targets):
        batch_size = predictions['coords'].shape[0]

        # 1. ç†±åœ–æå¤±
        pred_heatmap = predictions['heatmap']
        target_heatmap = targets['heatmap']

        # Resize ç›®æ¨™ç†±åœ–åˆ°é æ¸¬å°ºå¯¸
        if pred_heatmap.shape[2:] != target_heatmap.shape[2:]:
            target_heatmap = torch.nn.functional.interpolate(
                target_heatmap, size=pred_heatmap.shape[2:],
                mode='bilinear', align_corners=True
            )

        heatmap_loss = self.bce(pred_heatmap, target_heatmap)

        # 2. åº§æ¨™å›žæ­¸æå¤± (åªè¨ˆç®—æœ‰æ•ˆé»ž)
        pred_coords = predictions['coords']  # [B, N, 2]
        target_coords = targets['keypoints']  # [B, N, 2]
        valid_mask = targets['valid_mask']  # [B, N]

        # è¨ˆç®—MSE
        coord_diff = self.mse(pred_coords, target_coords)  # [B, N, 2]
        coord_diff = coord_diff.sum(dim=-1)  # [B, N]

        # åªè¨ˆç®—æœ‰æ•ˆé»žçš„æå¤±
        coord_loss = (coord_diff * valid_mask).sum() / (valid_mask.sum() + 1e-8)

        # 3. è¨ˆæ•¸æå¤±
        count_logits = predictions['count_logits']
        target_count = torch.tensor([t for t in targets['num_vertebrae']],
                                   dtype=torch.long, device=count_logits.device)
        count_loss = self.ce(count_logits, target_count)

        # ç¸½æå¤±
        total_loss = (self.alpha * heatmap_loss +
                     self.beta * coord_loss +
                     self.gamma * count_loss)

        return {
            'total_loss': total_loss,
            'heatmap_loss': heatmap_loss,
            'coord_loss': coord_loss,
            'count_loss': count_loss
        }


class VertebraTrainer:
    """æ¤Žé«”é ‚é»žæª¢æ¸¬è¨“ç·´å™¨"""

    def __init__(self, model, train_loader, val_loader, device, config):
        self.model = model.to(device)
        self.train_loader = train_loader
        self.val_loader = val_loader
        self.device = device
        self.config = config

        self.optimizer = optim.AdamW(
            model.parameters(),
            lr=config['learning_rate'],
            weight_decay=config['weight_decay']
        )
        self.scheduler = optim.lr_scheduler.CosineAnnealingLR(
            self.optimizer, T_max=config['epochs']
        )
        self.criterion = VertebraLoss()

        self.best_val_loss = float('inf')
        self.train_losses = []
        self.val_losses = []

    def train_epoch(self):
        """è¨“ç·´ä¸€å€‹ epoch"""
        self.model.train()
        total_loss = 0
        components = {'heatmap_loss': 0, 'coord_loss': 0, 'count_loss': 0}

        progress = tqdm(self.train_loader, desc='Training')
        for images, targets in progress:
            images = images.to(self.device)
            targets = {k: v.to(self.device) if isinstance(v, torch.Tensor) else v
                      for k, v in targets.items()}

            self.optimizer.zero_grad()
            predictions = self.model(images)
            losses = self.criterion(predictions, targets)

            losses['total_loss'].backward()
            self.optimizer.step()

            total_loss += losses['total_loss'].item()
            for key in components:
                components[key] += losses[key].item()

            progress.set_postfix({
                'Loss': f"{losses['total_loss'].item():.4f}",
                'Coord': f"{losses['coord_loss'].item():.4f}"
            })

        n = len(self.train_loader)
        return total_loss / n, {k: v / n for k, v in components.items()}

    def validate(self):
        """é©—è­‰"""
        self.model.eval()
        total_loss = 0
        components = {'heatmap_loss': 0, 'coord_loss': 0, 'count_loss': 0}

        with torch.no_grad():
            progress = tqdm(self.val_loader, desc='Validation')
            for images, targets in progress:
                images = images.to(self.device)
                targets = {k: v.to(self.device) if isinstance(v, torch.Tensor) else v
                          for k, v in targets.items()}

                predictions = self.model(images)
                losses = self.criterion(predictions, targets)

                total_loss += losses['total_loss'].item()
                for key in components:
                    components[key] += losses[key].item()

        n = len(self.val_loader)
        return total_loss / n, {k: v / n for k, v in components.items()}

    def train(self):
        """å®Œæ•´è¨“ç·´"""
        print(f"é–‹å§‹è¨“ç·´æ¤Žé«”é ‚é»žæª¢æ¸¬æ¨¡åž‹ V2")
        print(f"è¨­å‚™: {self.device}")
        print(f"Epochs: {self.config['epochs']}")
        print("-" * 50)

        for epoch in range(self.config['epochs']):
            print(f"\nEpoch {epoch+1}/{self.config['epochs']}")

            train_loss, train_comp = self.train_epoch()
            val_loss, val_comp = self.validate()

            self.train_losses.append(train_loss)
            self.val_losses.append(val_loss)

            print(f"Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}")
            print(f"  Heatmap: {train_comp['heatmap_loss']:.4f}")
            print(f"  Coord: {train_comp['coord_loss']:.4f}")
            print(f"  Count: {train_comp['count_loss']:.4f}")

            # ä¿å­˜æœ€ä½³æ¨¡åž‹
            if val_loss < self.best_val_loss:
                self.best_val_loss = val_loss
                torch.save({
                    'epoch': epoch,
                    'model_state_dict': self.model.state_dict(),
                    'optimizer_state_dict': self.optimizer.state_dict(),
                    'val_loss': val_loss,
                    'config': self.config
                }, 'best_vertebra_model.pth')
                print("âœ… ä¿å­˜æœ€ä½³æ¨¡åž‹")

            self.scheduler.step()

            # æ¯20å€‹epochä¿å­˜æª¢æŸ¥é»ž
            if (epoch + 1) % 20 == 0:
                torch.save({
                    'epoch': epoch,
                    'model_state_dict': self.model.state_dict(),
                    'val_loss': val_loss
                }, f'checkpoint_vertebra_epoch_{epoch+1}.pth')

        print("\nðŸŽ‰ è¨“ç·´å®Œæˆ!")
        print(f"æœ€ä½³é©—è­‰æå¤±: {self.best_val_loss:.4f}")


def get_transforms(is_training=True):
    """æ•¸æ“šè®Šæ›"""
    if is_training:
        return A.Compose([
            A.Resize(512, 512),
            A.HorizontalFlip(p=0.3),
            A.Rotate(limit=10, p=0.3),
            A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.3),
            A.GaussNoise(var_limit=(10, 50), p=0.2),
            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
            ToTensorV2()
        ], keypoint_params=A.KeypointParams(format='xy', remove_invisible=False))
    else:
        return A.Compose([
            A.Resize(512, 512),
            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
            ToTensorV2()
        ], keypoint_params=A.KeypointParams(format='xy', remove_invisible=False))


def collate_fn(batch):
    """è‡ªå®šç¾© collate å‡½æ•¸"""
    images = []
    targets = {
        'keypoints': [],
        'valid_mask': [],
        'heatmap': [],
        'num_vertebrae': [],
        'vertebra_names': []
    }

    for image, target in batch:
        images.append(image)
        targets['keypoints'].append(target['keypoints'])
        targets['valid_mask'].append(target['valid_mask'])
        targets['heatmap'].append(target['heatmap'])
        targets['num_vertebrae'].append(target['num_vertebrae'])
        targets['vertebra_names'].append(target['vertebra_names'])

    return (
        torch.stack(images, 0),
        {
            'keypoints': torch.stack(targets['keypoints'], 0),
            'valid_mask': torch.stack(targets['valid_mask'], 0),
            'heatmap': torch.stack(targets['heatmap'], 0),
            'num_vertebrae': targets['num_vertebrae'],
            'vertebra_names': targets['vertebra_names']
        }
    )


def main():
    """ä¸»å‡½æ•¸"""
    config = {
        'data_dir': '.',
        'train_annotations': 'endplate_training_data/annotations/train_annotations.json',
        'val_annotations': 'endplate_training_data/annotations/val_annotations.json',
        'batch_size': 4,
        'epochs': 100,
        'learning_rate': 1e-4,
        'weight_decay': 1e-4,
        'num_workers': 0,
        'max_vertebrae': 8
    }

    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"ä½¿ç”¨è¨­å‚™: {device}")

    # æª¢æŸ¥æ¨™è¨»æª”æ¡ˆ
    if not os.path.exists(config['train_annotations']):
        print(f"âŒ æ‰¾ä¸åˆ°è¨“ç·´æ¨™è¨»: {config['train_annotations']}")
        print("ðŸ’¡ è«‹å…ˆåŸ·è¡Œ prepare_endplate_data.py æº–å‚™æ•¸æ“š")
        print("ðŸ’¡ æˆ–ä½¿ç”¨ spinal-annotation-web.html é€²è¡Œæ¨™è¨»")
        return

    # æ•¸æ“šé›†
    train_dataset = VertebraDataset(
        config['data_dir'],
        config['train_annotations'],
        transform=get_transforms(True),
        max_vertebrae=config['max_vertebrae']
    )

    val_dataset = VertebraDataset(
        config['data_dir'],
        config['val_annotations'],
        transform=get_transforms(False),
        max_vertebrae=config['max_vertebrae']
    )

    train_loader = DataLoader(
        train_dataset,
        batch_size=config['batch_size'],
        shuffle=True,
        num_workers=config['num_workers'],
        collate_fn=collate_fn,
        pin_memory=True
    )

    val_loader = DataLoader(
        val_dataset,
        batch_size=config['batch_size'],
        shuffle=False,
        num_workers=config['num_workers'],
        collate_fn=collate_fn,
        pin_memory=True
    )

    # æ¨¡åž‹
    model = VertebraCornerModel(
        max_vertebrae=config['max_vertebrae'],
        pretrained=True
    )
    print(f"æ¨¡åž‹åƒæ•¸: {sum(p.numel() for p in model.parameters()):,}")

    # è¨“ç·´
    trainer = VertebraTrainer(model, train_loader, val_loader, device, config)
    trainer.train()


if __name__ == "__main__":
    main()

#!/usr/bin/env python3
"""
è„Šæ¤çµ‚æ¿æª¢æ¸¬ - æ©Ÿå™¨å­¸ç¿’è¨“ç·´è…³æœ¬
Spine Endplate Detection - ML Training Script

å°ˆæ³¨æ–¼æª¢æ¸¬çµ‚æ¿å‰å¾Œç·£ï¼Œä¸è¨ˆç®—è§’åº¦
åªè¼¸å‡ºendplateä½ç½®å’Œvertebra edges

ä½œè€…: AI Assistant
æ—¥æœŸ: 2025
"""

import os
import json
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms, models
import pydicom
import cv2
from PIL import Image
import matplotlib.pyplot as plt
from tqdm import tqdm
import albumentations as A
from albumentations.pytorch import ToTensorV2
import warnings
warnings.filterwarnings('ignore')

class EndplateDataset(Dataset):
    """çµ‚æ¿æª¢æ¸¬æ•¸æ“šé›†"""
    
    def __init__(self, data_dir, annotations_file, transform=None, is_training=True):
        self.data_dir = data_dir
        self.transform = transform
        self.is_training = is_training
        
        # è¼‰å…¥æ¨™è¨»æ•¸æ“š
        with open(annotations_file, 'r', encoding='utf-8') as f:
            self.annotations = json.load(f)
        
        # ç¢ºä¿æ˜¯listæ ¼å¼
        if isinstance(self.annotations, dict):
            self.annotations = [self.annotations]
        
        print(f"è¼‰å…¥ {len(self.annotations)} å€‹æ¨£æœ¬")
    
    def __len__(self):
        return len(self.annotations)
    
    def __getitem__(self, idx):
        annotation = self.annotations[idx]
        
        # è¼‰å…¥åœ–åƒ
        image_path = os.path.join(self.data_dir, annotation.get('image_path', ''))
        
        # å˜—è©¦è¼‰å…¥åœ–åƒ
        image = None
        
        # æ–¹æ³•1: ç›´æ¥è®€å–
        if os.path.exists(image_path):
            if image_path.lower().endswith('.dcm'):
                # DICOMæª”æ¡ˆ
                try:
                    dcm = pydicom.dcmread(image_path)
                    image = dcm.pixel_array
                    # è½‰æ›ç‚ºRGBæ ¼å¼
                    if len(image.shape) == 2:
                        image = np.stack([image] * 3, axis=-1)
                    # æ­£è¦åŒ–åˆ°0-255
                    image = ((image - image.min()) / (image.max() - image.min()) * 255).astype(np.uint8)
                except Exception as e:
                    print(f"Error loading DICOM {image_path}: {e}")
            else:
                # ä¸€èˆ¬åœ–åƒæª”æ¡ˆ
                image = cv2.imread(image_path)
                if image is not None:
                    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        
        # æ–¹æ³•2: å¦‚æœè·¯å¾‘ä¸å­˜åœ¨æˆ–è¼‰å…¥å¤±æ•—ï¼Œæœå°‹åŒåDICOM
        if image is None:
            # å¾æ¨™è¨»æª”æ¡ˆè·¯å¾‘æ¨æ¸¬
            base_name = os.path.splitext(os.path.basename(image_path))[0] if image_path else ''
            if base_name:
                # æœå°‹æ‰€æœ‰å¯èƒ½çš„DICOMæª”æ¡ˆ
                for root, dirs, files in os.walk(self.data_dir):
                    for file in files:
                        if file.startswith(base_name) and file.lower().endswith('.dcm'):
                            dcm_path = os.path.join(root, file)
                            try:
                                dcm = pydicom.dcmread(dcm_path)
                                image = dcm.pixel_array
                                if len(image.shape) == 2:
                                    image = np.stack([image] * 3, axis=-1)
                                image = ((image - image.min()) / (image.max() - image.min()) * 255).astype(np.uint8)
                                break
                            except:
                                continue
                    if image is not None:
                        break
        
        if image is None:
            raise FileNotFoundError(f"Cannot load image: {image_path} (searched in {self.data_dir})")
        
        # è™•ç†æ¨™è¨» - æ–°æ ¼å¼
        measurements = annotation.get('measurements', [])
        vertebra_edges = annotation.get('vertebra_edges', {})
        
        # æ‡‰ç”¨è®Šæ›ï¼ˆåŒ…å«åœ–åƒå’Œé®ç½©ï¼‰
        if self.transform:
            # å‰µå»ºåŸå§‹å°ºå¯¸çš„é®ç½©
            original_h, original_w = image.shape[:2]
            endplate_mask, vertebra_edge_mask = self.create_masks(measurements, vertebra_edges, (original_h, original_w))
            
            # æº–å‚™é—œéµé»
            keypoints = []
            for m in measurements:
                for p in m.get('lowerEndplate', []):
                    keypoints.append([p['x'], p['y']])
                for p in m.get('upperEndplate', []):
                    keypoints.append([p['x'], p['y']])
            
            # ä½¿ç”¨ä¸å«ToTensorV2çš„transformä¾†è™•ç†é®ç½©
            mask_transform = A.Compose([
                A.Resize(512, 512)
            ])
            
            # è®Šæ›é®ç½©
            mask_transformed = mask_transform(
                image=image,  # éœ€è¦imageåƒæ•¸
                masks=[endplate_mask, vertebra_edge_mask[:,:,0], vertebra_edge_mask[:,:,1]]
            )
            
            # è®Šæ›åœ–åƒå’Œé—œéµé»
            transformed = self.transform(image=image, keypoints=keypoints)
            
            image = transformed['image']
            masks = mask_transformed['masks']
            
            # çµ„åˆé®ç½©ï¼ˆä¿æŒnumpyæ ¼å¼ï¼‰
            endplate_mask_resized = masks[0]
            vertebra_edge_mask_resized = np.stack([masks[1], masks[2]], axis=-1)
            
            # å‰µå»ºç›®æ¨™
            targets = self.create_targets_from_masks(
                endplate_mask_resized,
                vertebra_edge_mask_resized,
                transformed.get('keypoints', []),
                measurements,
                image.shape[1:3]
            )
        else:
            # ç„¡è®Šæ›æ™‚ç›´æ¥å‰µå»º
            targets = self.create_targets(measurements, vertebra_edges, image.shape[:2])
        
        return image, targets
    
    def create_masks(self, measurements, vertebra_edges, image_shape):
        """å‰µå»ºé®ç½©ï¼ˆç”¨æ–¼transformï¼‰"""
        h, w = image_shape
        
        # çµ‚æ¿é®ç½©
        endplate_mask = np.zeros((h, w), dtype=np.float32)
        for m in measurements:
            if 'lowerEndplate' in m and len(m['lowerEndplate']) >= 2:
                p1, p2 = m['lowerEndplate'][0], m['lowerEndplate'][1]
                cv2.line(endplate_mask, (int(p1['x']), int(p1['y'])), (int(p2['x']), int(p2['y'])), 1.0, thickness=5)
            if 'upperEndplate' in m and len(m['upperEndplate']) >= 2:
                p1, p2 = m['upperEndplate'][0], m['upperEndplate'][1]
                cv2.line(endplate_mask, (int(p1['x']), int(p1['y'])), (int(p2['x']), int(p2['y'])), 1.0, thickness=5)
        
        # æ¤é«”é‚Šç·£é®ç½©
        anterior_mask = np.zeros((h, w), dtype=np.float32)
        posterior_mask = np.zeros((h, w), dtype=np.float32)
        for vertebra_name, edges in vertebra_edges.items():
            if 'anterior' in edges and len(edges['anterior']) >= 2:
                p1, p2 = edges['anterior'][0], edges['anterior'][1]
                cv2.line(anterior_mask, (int(p1['x']), int(p1['y'])), (int(p2['x']), int(p2['y'])), 1.0, thickness=5)
            if 'posterior' in edges and len(edges['posterior']) >= 2:
                p1, p2 = edges['posterior'][0], edges['posterior'][1]
                cv2.line(posterior_mask, (int(p1['x']), int(p1['y'])), (int(p2['x']), int(p2['y'])), 1.0, thickness=5)
        
        vertebra_edge_mask = np.stack([anterior_mask, posterior_mask], axis=-1)
        return endplate_mask, vertebra_edge_mask
    
    def create_targets_from_masks(self, endplate_mask, vertebra_edge_mask, keypoints, measurements, image_shape):
        """å¾è®Šæ›å¾Œçš„é®ç½©å‰µå»ºç›®æ¨™"""
        h, w = image_shape
        
        # è™•ç†é—œéµé»
        keypoint_list = []
        for kp in keypoints:
            if len(kp) >= 2:
                keypoint_list.append([kp[0]/w, kp[1]/h, 1.0])
        
        # é‚Šç•Œæ¡†ï¼ˆå¾measurementsè¨ˆç®—ï¼‰
        bboxes = []
        for m in measurements:
            all_points = []
            for p in m.get('lowerEndplate', []) + m.get('upperEndplate', []):
                all_points.append([p['x'], p['y']])
            if all_points:
                all_points = np.array(all_points)
                x_min, y_min = all_points.min(axis=0)
                x_max, y_max = all_points.max(axis=0)
                x_center = (x_min + x_max) / 2 / w
                y_center = (y_min + y_max) / 2 / h
                box_w = (x_max - x_min) / w
                box_h = (y_max - y_min) / h
                bboxes.append([x_center, y_center, box_w, box_h])
        
        # è½‰æ›ç‚ºå¼µé‡ï¼ˆé®ç½©ç¸½æ˜¯numpyæ ¼å¼ï¼‰
        endplate_tensor = torch.from_numpy(endplate_mask).unsqueeze(0).contiguous()
        vertebra_edge_tensor = torch.from_numpy(vertebra_edge_mask).permute(2, 0, 1).contiguous()
        
        return {
            'endplate_mask': endplate_tensor,
            'vertebra_edge_mask': vertebra_edge_tensor,
            'keypoints': torch.tensor(keypoint_list, dtype=torch.float32) if keypoint_list else torch.zeros((0, 3)),
            'bboxes': torch.tensor(bboxes, dtype=torch.float32) if bboxes else torch.zeros((0, 4)),
            'num_measurements': len(measurements)
        }
    
    def create_targets(self, measurements, vertebra_edges, image_shape):
        """å‰µå»ºè¨“ç·´ç›®æ¨™ - å°ˆæ³¨æ–¼çµ‚æ¿æª¢æ¸¬"""
        h, w = image_shape
        
        # 1. çµ‚æ¿åˆ†å‰²é®ç½© (ç·šæ®µå½¢å¼)
        endplate_mask = np.zeros((h, w), dtype=np.float32)
        
        for m in measurements:
            # ç¹ªè£½lowerEndplateç·šæ®µ
            if 'lowerEndplate' in m and len(m['lowerEndplate']) >= 2:
                p1 = m['lowerEndplate'][0]
                p2 = m['lowerEndplate'][1]
                cv2.line(endplate_mask, 
                        (int(p1['x']), int(p1['y'])),
                        (int(p2['x']), int(p2['y'])),
                        1.0, thickness=5)
            
            # ç¹ªè£½upperEndplateç·šæ®µ
            if 'upperEndplate' in m and len(m['upperEndplate']) >= 2:
                p1 = m['upperEndplate'][0]
                p2 = m['upperEndplate'][1]
                cv2.line(endplate_mask,
                        (int(p1['x']), int(p1['y'])),
                        (int(p2['x']), int(p2['y'])),
                        1.0, thickness=5)
        
        # 2. é—œéµé»ç†±åœ– (æ¯å€‹çµ‚æ¿ç«¯é»)
        num_keypoints = 0
        keypoint_list = []
        
        for m in measurements:
            # lowerEndplate 2å€‹é»
            for p in m.get('lowerEndplate', []):
                keypoint_list.append([p['x']/w, p['y']/h, 1.0])
                num_keypoints += 1
            # upperEndplate 2å€‹é»
            for p in m.get('upperEndplate', []):
                keypoint_list.append([p['x']/w, p['y']/h, 1.0])
                num_keypoints += 1
        
        # 3. æ¤é«”é‚Šç·£æª¢æ¸¬ç›®æ¨™
        vertebra_edge_mask = np.zeros((h, w, 2), dtype=np.float32)  # 2é€šé“: anterior, posterior
        
        # ç‚ºæ¯å€‹é€šé“å‰µå»ºç¨ç«‹çš„é®ç½©ï¼ˆè§£æ±ºè¨˜æ†¶é«”ä½ˆå±€å•é¡Œï¼‰
        anterior_mask = np.zeros((h, w), dtype=np.float32)
        posterior_mask = np.zeros((h, w), dtype=np.float32)
        
        for vertebra_name, edges in vertebra_edges.items():
            # Anterior edge
            if 'anterior' in edges and len(edges['anterior']) >= 2:
                p1 = edges['anterior'][0]
                p2 = edges['anterior'][1]
                cv2.line(anterior_mask,
                        (int(p1['x']), int(p1['y'])),
                        (int(p2['x']), int(p2['y'])),
                        1.0, thickness=5)
            
            # Posterior edge  
            if 'posterior' in edges and len(edges['posterior']) >= 2:
                p1 = edges['posterior'][0]
                p2 = edges['posterior'][1]
                cv2.line(posterior_mask,
                        (int(p1['x']), int(p1['y'])),
                        (int(p2['x']), int(p2['y'])),
                        1.0, thickness=5)
        
        # çµ„åˆåˆ°å¤šé€šé“é®ç½©
        vertebra_edge_mask[:,:,0] = anterior_mask
        vertebra_edge_mask[:,:,1] = posterior_mask
        
        # 4. æ¤é–“éš™é‚Šç•Œæ¡† (ç”¨æ–¼å®šä½)
        bboxes = []
        for m in measurements:
            # æ”¶é›†æ‰€æœ‰é»
            all_points = []
            for p in m.get('lowerEndplate', []):
                all_points.append([p['x'], p['y']])
            for p in m.get('upperEndplate', []):
                all_points.append([p['x'], p['y']])
            
            if all_points:
                all_points = np.array(all_points)
                x_min, y_min = all_points.min(axis=0)
                x_max, y_max = all_points.max(axis=0)
                
                # æ­£è¦åŒ–
                x_center = (x_min + x_max) / 2 / w
                y_center = (y_min + y_max) / 2 / h
                box_w = (x_max - x_min) / w
                box_h = (y_max - y_min) / h
                
                bboxes.append([x_center, y_center, box_w, box_h])
        
        # ç¢ºä¿å¼µé‡æ˜¯é€£çºŒçš„
        endplate_tensor = torch.from_numpy(endplate_mask).unsqueeze(0).contiguous()  # [1, H, W]
        vertebra_edge_tensor = torch.from_numpy(vertebra_edge_mask).permute(2, 0, 1).contiguous()  # [2, H, W]
        
        return {
            'endplate_mask': endplate_tensor,
            'vertebra_edge_mask': vertebra_edge_tensor,
            'keypoints': torch.tensor(keypoint_list, dtype=torch.float32),  # [N, 3]
            'bboxes': torch.tensor(bboxes, dtype=torch.float32),  # [M, 4]
            'num_measurements': len(measurements)
        }
    
    def _update_keypoints(self, transformed_keypoints, image_size):
        """æ›´æ–°è®Šæ›å¾Œçš„é—œéµé»"""
        h, w = image_size
        kp_list = []
        for kp in transformed_keypoints:
            kp_list.append([kp[0]/w, kp[1]/h, 1.0])
        return torch.tensor(kp_list, dtype=torch.float32)

class EndplateDetectionModel(nn.Module):
    """çµ‚æ¿æª¢æ¸¬æ¨¡å‹ - U-Netæ¶æ§‹"""
    
    def __init__(self, pretrained=True):
        super(EndplateDetectionModel, self).__init__()
        
        # Encoder - ResNet50 backbone
        resnet = models.resnet50(pretrained=pretrained)
        self.encoder1 = nn.Sequential(*list(resnet.children())[:3])  # 64
        self.encoder2 = nn.Sequential(*list(resnet.children())[3:5])  # 256
        self.encoder3 = resnet.layer2  # 512
        self.encoder4 = resnet.layer3  # 1024
        self.encoder5 = resnet.layer4  # 2048
        
        # Decoder for endplate segmentation
        self.up1 = self._make_upconv(2048, 1024)
        self.dec1 = self._make_conv_block(2048, 1024)
        
        self.up2 = self._make_upconv(1024, 512)
        self.dec2 = self._make_conv_block(1024, 512)
        
        self.up3 = self._make_upconv(512, 256)
        self.dec3 = self._make_conv_block(512, 256)
        
        self.up4 = self._make_upconv(256, 64)
        self.dec4 = self._make_conv_block(128, 64)
        
        # Output heads
        # 1. Endplate segmentation (çµ‚æ¿ç·šæ®µ)
        self.endplate_out = nn.Conv2d(64, 1, 1)
        
        # 2. Vertebra edge segmentation (å‰å¾Œç·£)
        self.vertebra_edge_out = nn.Conv2d(64, 2, 1)  # 2é€šé“: anterior, posterior
        
        # 3. Keypoint heatmap (é—œéµé»)
        self.keypoint_out = nn.Conv2d(64, 1, 1)
        
    def _make_upconv(self, in_channels, out_channels):
        return nn.ConvTranspose2d(in_channels, out_channels, 2, stride=2)
    
    def _make_conv_block(self, in_channels, out_channels):
        return nn.Sequential(
            nn.Conv2d(in_channels, out_channels, 3, padding=1),
            nn.BatchNorm2d(out_channels),
            nn.ReLU(inplace=True),
            nn.Conv2d(out_channels, out_channels, 3, padding=1),
            nn.BatchNorm2d(out_channels),
            nn.ReLU(inplace=True)
        )
    
    def forward(self, x):
        # Encoder
        e1 = self.encoder1(x)  # [B, 64, H/2, W/2]
        e2 = self.encoder2(e1)  # [B, 256, H/4, W/4]
        e3 = self.encoder3(e2)  # [B, 512, H/8, W/8]
        e4 = self.encoder4(e3)  # [B, 1024, H/16, W/16]
        e5 = self.encoder5(e4)  # [B, 2048, H/32, W/32]
        
        # Decoder
        d1 = self.up1(e5)
        d1 = torch.cat([d1, e4], dim=1)
        d1 = self.dec1(d1)
        
        d2 = self.up2(d1)
        d2 = torch.cat([d2, e3], dim=1)
        d2 = self.dec2(d2)
        
        d3 = self.up3(d2)
        d3 = torch.cat([d3, e2], dim=1)
        d3 = self.dec3(d3)
        
        d4 = self.up4(d3)
        d4 = torch.cat([d4, e1], dim=1)
        d4 = self.dec4(d4)
        
        # Outputs
        endplate_seg = torch.sigmoid(self.endplate_out(d4))
        vertebra_edge_seg = torch.sigmoid(self.vertebra_edge_out(d4))
        keypoint_heatmap = torch.sigmoid(self.keypoint_out(d4))
        
        return {
            'endplate_seg': endplate_seg,
            'vertebra_edge_seg': vertebra_edge_seg,
            'keypoint_heatmap': keypoint_heatmap
        }

class EndplateLoss(nn.Module):
    """çµ‚æ¿æª¢æ¸¬æå¤±å‡½æ•¸"""
    
    def __init__(self, alpha=1.0, beta=1.0, gamma=0.5):
        super(EndplateLoss, self).__init__()
        self.alpha = alpha
        self.beta = beta
        self.gamma = gamma
        
        self.bce_loss = nn.BCELoss()
        self.mse_loss = nn.MSELoss()
    
    def forward(self, predictions, targets):
        # ç²å–é æ¸¬çš„å°ºå¯¸
        pred_h, pred_w = predictions['endplate_seg'].shape[2:4]
        
        # Resizeç›®æ¨™åˆ°é æ¸¬å°ºå¯¸
        import torch.nn.functional as F
        endplate_mask_resized = F.interpolate(
            targets['endplate_mask'], 
            size=(pred_h, pred_w), 
            mode='bilinear', 
            align_corners=False
        )
        vertebra_edge_mask_resized = F.interpolate(
            targets['vertebra_edge_mask'], 
            size=(pred_h, pred_w), 
            mode='bilinear', 
            align_corners=False
        )
        
        # 1. Endplate segmentation loss
        endplate_loss = self.bce_loss(
            predictions['endplate_seg'],
            endplate_mask_resized
        )
        
        # 2. Vertebra edge segmentation loss
        edge_loss = self.bce_loss(
            predictions['vertebra_edge_seg'],
            vertebra_edge_mask_resized
        )
        
        # 3. Keypoint heatmap loss
        # å‰µå»ºé«˜æ–¯ç†±åœ–
        keypoint_heatmap = self._create_keypoint_heatmap(
            targets['keypoints'],
            predictions['keypoint_heatmap'].shape[2:4]
        )
        keypoint_loss = self.mse_loss(
            predictions['keypoint_heatmap'],
            keypoint_heatmap.unsqueeze(1)
        )
        
        # ç¸½æå¤±
        total_loss = (self.alpha * endplate_loss +
                     self.beta * edge_loss +
                     self.gamma * keypoint_loss)
        
        return {
            'total_loss': total_loss,
            'endplate_loss': endplate_loss,
            'edge_loss': edge_loss,
            'keypoint_loss': keypoint_loss
        }
    
    def _create_keypoint_heatmap(self, keypoints, output_size):
        """å‰µå»ºé—œéµé»é«˜æ–¯ç†±åœ–ï¼ˆè™•ç†listæ ¼å¼ï¼‰"""
        h, w = output_size
        
        # keypoints ç¾åœ¨æ˜¯ list of tensors
        if isinstance(keypoints, list):
            batch_size = len(keypoints)
            device = keypoints[0].device if len(keypoints) > 0 and keypoints[0].numel() > 0 else 'cpu'
        else:
            batch_size = keypoints.shape[0]
            device = keypoints.device
        
        heatmap = torch.zeros(batch_size, h, w, device=device)
        
        for b in range(batch_size):
            kp_batch = keypoints[b] if isinstance(keypoints, list) else keypoints[b]
            
            if kp_batch.numel() == 0:  # æ²’æœ‰é—œéµé»
                continue
                
            for kp in kp_batch:
                if len(kp) >= 3 and kp[2] > 0:  # visibility
                    x, y = int(kp[0] * w), int(kp[1] * h)
                    if 0 <= x < w and 0 <= y < h:
                        # ç°¡å–®çš„é»æ¨™è¨˜
                        heatmap[b, y, x] = 1.0
        
        return heatmap

class EndplateTrainer:
    """çµ‚æ¿æª¢æ¸¬è¨“ç·´å™¨"""
    
    def __init__(self, model, train_loader, val_loader, device, config):
        self.model = model.to(device)
        self.train_loader = train_loader
        self.val_loader = val_loader
        self.device = device
        self.config = config
        
        # å„ªåŒ–å™¨å’Œèª¿åº¦å™¨
        self.optimizer = optim.AdamW(
            model.parameters(),
            lr=config['learning_rate'],
            weight_decay=config['weight_decay']
        )
        self.scheduler = optim.lr_scheduler.CosineAnnealingLR(
            self.optimizer,
            T_max=config['epochs']
        )
        self.criterion = EndplateLoss()
        
        # è¨“ç·´è¨˜éŒ„
        self.best_val_loss = float('inf')
        self.train_losses = []
        self.val_losses = []
    
    def train_epoch(self):
        """è¨“ç·´ä¸€å€‹epoch"""
        self.model.train()
        total_loss = 0
        loss_components = {
            'endplate_loss': 0,
            'edge_loss': 0,
            'keypoint_loss': 0
        }
        
        progress_bar = tqdm(self.train_loader, desc='Training')
        for batch_idx, (images, targets) in enumerate(progress_bar):
            images = images.to(self.device)
            targets = {k: v.to(self.device) if isinstance(v, torch.Tensor) else v 
                      for k, v in targets.items()}
            
            self.optimizer.zero_grad()
            
            predictions = self.model(images)
            losses = self.criterion(predictions, targets)
            
            losses['total_loss'].backward()
            self.optimizer.step()
            
            # è¨˜éŒ„æå¤±
            total_loss += losses['total_loss'].item()
            for key in loss_components:
                loss_components[key] += losses[key].item()
            
            # æ›´æ–°é€²åº¦æ¢
            progress_bar.set_postfix({
                'Loss': f"{losses['total_loss'].item():.4f}",
                'LR': f"{self.optimizer.param_groups[0]['lr']:.6f}"
            })
        
        # è¨ˆç®—å¹³å‡æå¤±
        avg_loss = total_loss / len(self.train_loader)
        for key in loss_components:
            loss_components[key] /= len(self.train_loader)
        
        return avg_loss, loss_components
    
    def validate(self):
        """é©—è­‰æ¨¡å‹"""
        self.model.eval()
        total_loss = 0
        loss_components = {
            'endplate_loss': 0,
            'edge_loss': 0,
            'keypoint_loss': 0
        }
        
        with torch.no_grad():
            progress_bar = tqdm(self.val_loader, desc='Validation')
            for images, targets in progress_bar:
                images = images.to(self.device)
                targets = {k: v.to(self.device) if isinstance(v, torch.Tensor) else v
                          for k, v in targets.items()}
                
                predictions = self.model(images)
                losses = self.criterion(predictions, targets)
                
                total_loss += losses['total_loss'].item()
                for key in loss_components:
                    loss_components[key] += losses[key].item()
                
                progress_bar.set_postfix({'Val Loss': f"{losses['total_loss'].item():.4f}"})
        
        # è¨ˆç®—å¹³å‡æå¤±
        avg_loss = total_loss / len(self.val_loader)
        for key in loss_components:
            loss_components[key] /= len(self.val_loader)
        
        return avg_loss, loss_components
    
    def train(self):
        """å®Œæ•´è¨“ç·´æµç¨‹"""
        print(f"é–‹å§‹è¨“ç·´çµ‚æ¿æª¢æ¸¬æ¨¡å‹ï¼Œå…± {self.config['epochs']} å€‹epochs")
        print(f"è¨­å‚™: {self.device}")
        print(f"æ‰¹æ¬¡å¤§å°: {self.config['batch_size']}")
        print(f"å­¸ç¿’ç‡: {self.config['learning_rate']}")
        print("-" * 50)
        
        for epoch in range(self.config['epochs']):
            print(f"\nEpoch {epoch+1}/{self.config['epochs']}")
            
            # è¨“ç·´
            train_loss, train_components = self.train_epoch()
            self.train_losses.append(train_loss)
            
            # é©—è­‰
            val_loss, val_components = self.validate()
            self.val_losses.append(val_loss)
            
            # æ‰“å°çµæœ
            print(f"Train Loss: {train_loss:.4f}")
            print(f"Val Loss: {val_loss:.4f}")
            print("Loss Components:")
            for key, value in train_components.items():
                print(f"  {key}: {value:.4f}")
            
            # ä¿å­˜æœ€ä½³æ¨¡å‹
            if val_loss < self.best_val_loss:
                self.best_val_loss = val_loss
                torch.save({
                    'epoch': epoch,
                    'model_state_dict': self.model.state_dict(),
                    'optimizer_state_dict': self.optimizer.state_dict(),
                    'val_loss': val_loss,
                    'config': self.config
                }, 'best_endplate_model.pth')
                print("âœ… ä¿å­˜æœ€ä½³æ¨¡å‹")
            
            # å­¸ç¿’ç‡èª¿åº¦
            self.scheduler.step()
            
            # æ¯10å€‹epochä¿å­˜æª¢æŸ¥é»
            if (epoch + 1) % 10 == 0:
                torch.save({
                    'epoch': epoch,
                    'model_state_dict': self.model.state_dict(),
                    'optimizer_state_dict': self.optimizer.state_dict(),
                    'val_loss': val_loss,
                    'config': self.config
                }, f'checkpoint_epoch_{epoch+1}.pth')
        
        print("\nğŸ‰ è¨“ç·´å®Œæˆ!")
        print(f"æœ€ä½³é©—è­‰æå¤±: {self.best_val_loss:.4f}")

def get_transforms(is_training=True):
    """ç²å–æ•¸æ“šè®Šæ›"""
    if is_training:
        return A.Compose([
            A.Resize(512, 512),
            A.HorizontalFlip(p=0.3),
            A.Rotate(limit=10, p=0.3),
            A.RandomBrightnessContrast(p=0.3),
            A.GaussNoise(p=0.2),
            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
            ToTensorV2()
        ], 
        keypoint_params=A.KeypointParams(format='xy', remove_invisible=False))
    else:
        return A.Compose([
            A.Resize(512, 512),
            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
            ToTensorV2()
        ], 
        keypoint_params=A.KeypointParams(format='xy', remove_invisible=False))

def custom_collate_fn(batch):
    """è‡ªå®šç¾©collateå‡½æ•¸ï¼Œè™•ç†å¯è®Šé•·åº¦çš„é—œéµé»å’Œé‚Šç•Œæ¡†"""
    images = []
    targets = {
        'endplate_mask': [],
        'vertebra_edge_mask': [],
        'keypoints': [],
        'bboxes': [],
        'num_measurements': []
    }
    
    for image, target in batch:
        images.append(image)
        targets['endplate_mask'].append(target['endplate_mask'])
        targets['vertebra_edge_mask'].append(target['vertebra_edge_mask'])
        targets['keypoints'].append(target['keypoints'])  # ä¿æŒç‚ºlistï¼Œä¸stack
        targets['bboxes'].append(target['bboxes'])  # ä¿æŒç‚ºlistï¼Œä¸stack
        targets['num_measurements'].append(target['num_measurements'])
    
    # Stackå›ºå®šå°ºå¯¸çš„å¼µé‡
    batched = {
        'endplate_mask': torch.stack(targets['endplate_mask'], 0),
        'vertebra_edge_mask': torch.stack(targets['vertebra_edge_mask'], 0),
        'keypoints': targets['keypoints'],  # List of tensors
        'bboxes': targets['bboxes'],  # List of tensors
        'num_measurements': torch.tensor(targets['num_measurements'])
    }
    
    return torch.stack(images, 0), batched

def main():
    """ä¸»å‡½æ•¸"""
    # é…ç½®åƒæ•¸
    config = {
        'data_dir': '.',  # ç•¶å‰ç›®éŒ„ï¼ˆåŸ·è¡Œæ™‚æ‡‰åœ¨ Spine è³‡æ–™å¤¾ä¸­ï¼‰
        'train_annotations': 'endplate_training_data/annotations/train_annotations.json',
        'val_annotations': 'endplate_training_data/annotations/val_annotations.json',
        'batch_size': 4,
        'epochs': 100,
        'learning_rate': 1e-4,
        'weight_decay': 1e-4,
        'num_workers': 0  # è¨­ç‚º0é¿å…å¤šé€²ç¨‹å•é¡Œï¼ˆWindowsï¼‰
    }
    
    # è¨­å‚™è¨­ç½®
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"ä½¿ç”¨è¨­å‚™: {device}")
    
    # å‰µå»ºæ•¸æ“šé›†
    train_transform = get_transforms(is_training=True)
    val_transform = get_transforms(is_training=False)
    
    train_dataset = EndplateDataset(
        config['data_dir'],
        config['train_annotations'],
        transform=train_transform
    )
    val_dataset = EndplateDataset(
        config['data_dir'],
        config['val_annotations'],
        transform=val_transform
    )
    
    # å‰µå»ºæ•¸æ“šè¼‰å…¥å™¨ï¼ˆä½¿ç”¨è‡ªå®šç¾©collateï¼‰
    train_loader = DataLoader(
        train_dataset,
        batch_size=config['batch_size'],
        shuffle=True,
        num_workers=config['num_workers'],
        pin_memory=True,
        collate_fn=custom_collate_fn  # è‡ªå®šç¾©collate
    )
    val_loader = DataLoader(
        val_dataset,
        batch_size=config['batch_size'],
        shuffle=False,
        num_workers=config['num_workers'],
        pin_memory=True,
        collate_fn=custom_collate_fn  # è‡ªå®šç¾©collate
    )
    
    # å‰µå»ºæ¨¡å‹
    model = EndplateDetectionModel(pretrained=True)
    print(f"æ¨¡å‹åƒæ•¸æ•¸é‡: {sum(p.numel() for p in model.parameters()):,}")
    
    # å‰µå»ºè¨“ç·´å™¨
    trainer = EndplateTrainer(model, train_loader, val_loader, device, config)
    
    # é–‹å§‹è¨“ç·´
    trainer.train()

if __name__ == "__main__":
    main()

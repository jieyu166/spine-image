#!/usr/bin/env python3
"""
å¿«é€Ÿæ¸¬è©¦çµ‚æ¿æª¢æ¸¬æ¨¡å‹
Quick Test for Endplate Detection Model

ç”¨æ–¼æ¸¬è©¦æ¨¡å‹åœ¨å°‘é‡æ¨™è¨»æ•¸æ“šä¸Šçš„è¡¨ç¾
"""

import os
import json
import torch
import torch.nn as nn
import numpy as np
import cv2
import matplotlib.pyplot as plt
from pathlib import Path
from train_endplate_model import EndplateDetectionModel, EndplateDataset, get_transforms
import warnings
warnings.filterwarnings('ignore')

class QuickTester:
    """å¿«é€Ÿæ¸¬è©¦å™¨"""
    
    def __init__(self, data_dir, device='cpu'):
        self.data_dir = Path(data_dir)
        self.device = torch.device(device if torch.cuda.is_available() else 'cpu')
        self.model = None
        
        print(f"ğŸ”§ ä½¿ç”¨è¨­å‚™: {self.device}")
    
    def collect_annotations(self):
        """æ”¶é›†æ‰€æœ‰æ¨™è¨»æª”æ¡ˆ"""
        print("\nğŸ“ æ”¶é›†æ¨™è¨»æª”æ¡ˆ...")
        
        json_files = list(self.data_dir.glob('**/*.json'))
        valid_annotations = []
        
        for json_file in json_files:
            try:
                with open(json_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                
                # æª¢æŸ¥å¿…è¦æ¬„ä½
                if 'measurements' in data and len(data['measurements']) > 0:
                    valid_annotations.append({
                        'file': json_file,
                        'data': data
                    })
                    print(f"  âœ… {json_file.name}: {len(data['measurements'])} å€‹æ¤é–“éš™")
            
            except Exception as e:
                print(f"  âš ï¸ è·³é {json_file.name}: {e}")
        
        print(f"\nâœ… æ‰¾åˆ° {len(valid_annotations)} å€‹æœ‰æ•ˆæ¨™è¨»æª”æ¡ˆ")
        return valid_annotations
    
    def create_test_model(self):
        """å‰µå»ºæ¸¬è©¦æ¨¡å‹"""
        print("\nğŸ¤– å‰µå»ºæ¸¬è©¦æ¨¡å‹...")
        
        self.model = EndplateDetectionModel(pretrained=False)  # ä¸ä½¿ç”¨é è¨“ç·´ï¼Œæ›´å¿«
        self.model = self.model.to(self.device)
        self.model.eval()
        
        # è¨ˆç®—åƒæ•¸æ•¸é‡
        total_params = sum(p.numel() for p in self.model.parameters())
        trainable_params = sum(p.numel() for p in self.model.parameters() if p.requires_grad)
        
        print(f"  ç¸½åƒæ•¸: {total_params:,}")
        print(f"  å¯è¨“ç·´åƒæ•¸: {trainable_params:,}")
        print(f"  æ¨¡å‹å¤§å°: ~{total_params * 4 / 1024 / 1024:.1f} MB")
        
        return self.model
    
    def test_forward_pass(self, test_image_path=None):
        """æ¸¬è©¦å‰å‘å‚³æ’­"""
        print("\nğŸ”¬ æ¸¬è©¦å‰å‘å‚³æ’­...")
        
        # å‰µå»ºæ¸¬è©¦åœ–åƒ
        if test_image_path and os.path.exists(test_image_path):
            image = cv2.imread(test_image_path)
            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        else:
            # å‰µå»ºéš¨æ©Ÿæ¸¬è©¦åœ–åƒ
            image = np.random.randint(0, 255, (512, 512, 3), dtype=np.uint8)
            print("  âš ï¸ ä½¿ç”¨éš¨æ©Ÿæ¸¬è©¦åœ–åƒ")
        
        # é è™•ç†
        transform = get_transforms(is_training=False)
        transformed = transform(image=image)
        input_tensor = transformed['image'].unsqueeze(0).to(self.device)
        
        print(f"  è¼¸å…¥å½¢ç‹€: {input_tensor.shape}")
        
        # å‰å‘å‚³æ’­
        with torch.no_grad():
            outputs = self.model(input_tensor)
        
        # æª¢æŸ¥è¼¸å‡º
        print("\n  è¼¸å‡ºæª¢æŸ¥:")
        for key, value in outputs.items():
            print(f"    {key}: {value.shape}")
            print(f"      - ç¯„åœ: [{value.min():.4f}, {value.max():.4f}]")
            print(f"      - å¹³å‡å€¼: {value.mean():.4f}")
        
        return outputs
    
    def visualize_model_output(self, image_path, output_path='test_output.png'):
        """è¦–è¦ºåŒ–æ¨¡å‹è¼¸å‡º"""
        print(f"\nğŸ¨ è¦–è¦ºåŒ–æ¨¡å‹è¼¸å‡º...")
        
        if not os.path.exists(image_path):
            print(f"  âŒ åœ–åƒä¸å­˜åœ¨: {image_path}")
            return
        
        # è®€å–åœ–åƒ
        image = cv2.imread(image_path)
        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        original_size = image.shape[:2]
        
        # é è™•ç†
        transform = get_transforms(is_training=False)
        transformed = transform(image=image)
        input_tensor = transformed['image'].unsqueeze(0).to(self.device)
        
        # æ¨ç†
        with torch.no_grad():
            outputs = self.model(input_tensor)
        
        # æå–è¼¸å‡º
        endplate_seg = outputs['endplate_seg'][0, 0].cpu().numpy()
        vertebra_edge_seg = outputs['vertebra_edge_seg'][0].cpu().numpy()
        keypoint_heatmap = outputs['keypoint_heatmap'][0, 0].cpu().numpy()
        
        # èª¿æ•´å¤§å°å›åŸå§‹å°ºå¯¸
        endplate_seg = cv2.resize(endplate_seg, (original_size[1], original_size[0]))
        vertebra_edge_ant = cv2.resize(vertebra_edge_seg[0], (original_size[1], original_size[0]))
        vertebra_edge_post = cv2.resize(vertebra_edge_seg[1], (original_size[1], original_size[0]))
        keypoint_heatmap = cv2.resize(keypoint_heatmap, (original_size[1], original_size[0]))
        
        # å‰µå»ºè¦–è¦ºåŒ–
        fig, axes = plt.subplots(2, 3, figsize=(18, 12))
        fig.suptitle('çµ‚æ¿æª¢æ¸¬æ¨¡å‹è¼¸å‡º (æœªè¨“ç·´)', fontsize=16, fontweight='bold')
        
        # åŸå§‹åœ–åƒ
        axes[0, 0].imshow(image)
        axes[0, 0].set_title('åŸå§‹åœ–åƒ')
        axes[0, 0].axis('off')
        
        # çµ‚æ¿åˆ†å‰²
        axes[0, 1].imshow(image)
        axes[0, 1].imshow(endplate_seg, alpha=0.5, cmap='jet')
        axes[0, 1].set_title('çµ‚æ¿åˆ†å‰²é®ç½©\n(ç´…è‰²=æª¢æ¸¬åˆ°çš„çµ‚æ¿)')
        axes[0, 1].axis('off')
        
        # å‰ç·£æª¢æ¸¬
        axes[0, 2].imshow(image)
        axes[0, 2].imshow(vertebra_edge_ant, alpha=0.5, cmap='Blues')
        axes[0, 2].set_title('å‰ç·£æª¢æ¸¬\n(è—è‰²=anterior edge)')
        axes[0, 2].axis('off')
        
        # å¾Œç·£æª¢æ¸¬
        axes[1, 0].imshow(image)
        axes[1, 0].imshow(vertebra_edge_post, alpha=0.5, cmap='Oranges')
        axes[1, 0].set_title('å¾Œç·£æª¢æ¸¬\n(æ©™è‰²=posterior edge)')
        axes[1, 0].axis('off')
        
        # é—œéµé»ç†±åœ–
        axes[1, 1].imshow(image)
        axes[1, 1].imshow(keypoint_heatmap, alpha=0.5, cmap='hot')
        axes[1, 1].set_title('é—œéµé»ç†±åœ–\n(äº®é»=çµ‚æ¿ç«¯é»)')
        axes[1, 1].axis('off')
        
        # ç¶œåˆè¦–åœ–
        axes[1, 2].imshow(image)
        axes[1, 2].imshow(endplate_seg, alpha=0.3, cmap='Reds')
        axes[1, 2].imshow(vertebra_edge_ant, alpha=0.3, cmap='Blues')
        axes[1, 2].imshow(vertebra_edge_post, alpha=0.3, cmap='Oranges')
        axes[1, 2].set_title('ç¶œåˆè¦–åœ–\n(ç´…=çµ‚æ¿, è—=å‰ç·£, æ©™=å¾Œç·£)')
        axes[1, 2].axis('off')
        
        plt.tight_layout()
        plt.savefig(output_path, dpi=150, bbox_inches='tight')
        print(f"  âœ… è¦–è¦ºåŒ–çµæœå·²å„²å­˜: {output_path}")
        
        return fig
    
    def quick_training_test(self, annotations, num_epochs=5):
        """å¿«é€Ÿè¨“ç·´æ¸¬è©¦ï¼ˆå°‘é‡epochï¼‰"""
        print(f"\nğŸ‹ï¸ å¿«é€Ÿè¨“ç·´æ¸¬è©¦ ({num_epochs} epochs)...")
        
        if len(annotations) == 0:
            print("  âŒ æ²’æœ‰æ¨™è¨»æ•¸æ“šï¼Œç„¡æ³•è¨“ç·´")
            return
        
        # æº–å‚™æ•¸æ“š
        print("  æº–å‚™è¨“ç·´æ•¸æ“š...")
        train_data = []
        for ann in annotations[:min(len(annotations), 10)]:  # æœ€å¤š10å€‹æ¨£æœ¬
            train_data.append(ann['data'])
        
        # å‰µå»ºè‡¨æ™‚æ¨™è¨»æª”æ¡ˆ
        temp_file = 'temp_annotations.json'
        with open(temp_file, 'w', encoding='utf-8') as f:
            json.dump(train_data, f, ensure_ascii=False, indent=2)
        
        try:
            # å‰µå»ºæ•¸æ“šé›†
            transform = get_transforms(is_training=True)
            dataset = EndplateDataset(str(self.data_dir), temp_file, transform=transform)
            
            # å‰µå»ºæ•¸æ“šè¼‰å…¥å™¨
            from torch.utils.data import DataLoader
            loader = DataLoader(dataset, batch_size=2, shuffle=True)
            
            # å‰µå»ºå„ªåŒ–å™¨å’Œæå¤±å‡½æ•¸
            optimizer = torch.optim.Adam(self.model.parameters(), lr=1e-4)
            from train_endplate_model import EndplateLoss
            criterion = EndplateLoss()
            
            # è¨“ç·´
            self.model.train()
            losses = []
            
            for epoch in range(num_epochs):
                epoch_loss = 0
                for batch_idx, (images, targets) in enumerate(loader):
                    images = images.to(self.device)
                    targets = {k: v.to(self.device) if isinstance(v, torch.Tensor) else v 
                             for k, v in targets.items()}
                    
                    optimizer.zero_grad()
                    predictions = self.model(images)
                    loss_dict = criterion(predictions, targets)
                    
                    loss_dict['total_loss'].backward()
                    optimizer.step()
                    
                    epoch_loss += loss_dict['total_loss'].item()
                
                avg_loss = epoch_loss / len(loader)
                losses.append(avg_loss)
                print(f"  Epoch {epoch+1}/{num_epochs}: Loss = {avg_loss:.4f}")
            
            # ç¹ªè£½æå¤±æ›²ç·š
            plt.figure(figsize=(10, 6))
            plt.plot(losses, marker='o')
            plt.title('å¿«é€Ÿè¨“ç·´æ¸¬è©¦ - æå¤±æ›²ç·š')
            plt.xlabel('Epoch')
            plt.ylabel('Loss')
            plt.grid(True)
            plt.savefig('quick_training_loss.png', dpi=150, bbox_inches='tight')
            print(f"\n  âœ… æå¤±æ›²ç·šå·²å„²å­˜: quick_training_loss.png")
            
        finally:
            # æ¸…ç†è‡¨æ™‚æª”æ¡ˆ
            if os.path.exists(temp_file):
                os.remove(temp_file)
    
    def generate_test_report(self, annotations):
        """ç”Ÿæˆæ¸¬è©¦å ±å‘Š"""
        print("\nğŸ“Š ç”Ÿæˆæ¸¬è©¦å ±å‘Š...")
        
        report = {
            "test_date": str(Path().absolute()),
            "device": str(self.device),
            "dataset_info": {
                "total_annotations": len(annotations),
                "total_measurements": sum(len(a['data']['measurements']) for a in annotations),
                "spine_types": {},
                "image_types": {}
            },
            "model_info": {
                "architecture": "U-Net with ResNet50",
                "total_parameters": sum(p.numel() for p in self.model.parameters()),
                "trainable_parameters": sum(p.numel() for p in self.model.parameters() if p.requires_grad)
            }
        }
        
        # çµ±è¨ˆè³‡è¨Š
        for ann in annotations:
            data = ann['data']
            spine_type = data.get('spine_type', 'Unknown')
            image_type = data.get('image_type', 'Unknown')
            
            report['dataset_info']['spine_types'][spine_type] = \
                report['dataset_info']['spine_types'].get(spine_type, 0) + 1
            report['dataset_info']['image_types'][image_type] = \
                report['dataset_info']['image_types'].get(image_type, 0) + 1
        
        # å„²å­˜å ±å‘Š
        with open('test_report.json', 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2)
        
        print("  âœ… æ¸¬è©¦å ±å‘Šå·²å„²å­˜: test_report.json")
        
        # åˆ—å°æ‘˜è¦
        print("\n" + "="*50)
        print("æ¸¬è©¦æ‘˜è¦")
        print("="*50)
        print(f"æ¨™è¨»æª”æ¡ˆæ•¸: {report['dataset_info']['total_annotations']}")
        print(f"ç¸½æ¤é–“éš™æ•¸: {report['dataset_info']['total_measurements']}")
        print(f"è„Šæ¤é¡å‹: {report['dataset_info']['spine_types']}")
        print(f"å½±åƒé¡å‹: {report['dataset_info']['image_types']}")
        print(f"æ¨¡å‹åƒæ•¸: {report['model_info']['total_parameters']:,}")
        print("="*50)
        
        return report

def main():
    """ä¸»å‡½æ•¸"""
    print("="*60)
    print("ğŸš€ çµ‚æ¿æª¢æ¸¬æ¨¡å‹å¿«é€Ÿæ¸¬è©¦")
    print("="*60)
    
    # è¨­å®šè·¯å¾‘
    data_dir = '0. Inbox/Spine'
    
    # å‰µå»ºæ¸¬è©¦å™¨
    tester = QuickTester(data_dir, device='cuda')  # æˆ– 'cpu'
    
    # æ­¥é©Ÿ1: æ”¶é›†æ¨™è¨»
    annotations = tester.collect_annotations()
    
    if len(annotations) == 0:
        print("\nâŒ æœªæ‰¾åˆ°æœ‰æ•ˆçš„æ¨™è¨»æ•¸æ“šï¼Œç„¡æ³•ç¹¼çºŒæ¸¬è©¦")
        return
    
    # æ­¥é©Ÿ2: å‰µå»ºæ¨¡å‹
    tester.create_test_model()
    
    # æ­¥é©Ÿ3: æ¸¬è©¦å‰å‘å‚³æ’­
    tester.test_forward_pass()
    
    # æ­¥é©Ÿ4: è¦–è¦ºåŒ–è¼¸å‡ºï¼ˆä½¿ç”¨ç¬¬ä¸€å€‹æ¨™è¨»çš„åœ–åƒï¼‰
    first_ann = annotations[0]
    image_path = first_ann['data'].get('image_path', '')
    
    # å˜—è©¦æ‰¾åˆ°å°æ‡‰çš„DICOMæª”æ¡ˆ
    if not os.path.exists(image_path):
        # å°‹æ‰¾åŒåçš„.dcmæª”æ¡ˆ
        json_path = first_ann['file']
        dcm_path = json_path.with_suffix('.dcm')
        if dcm_path.exists():
            print(f"\nâœ… æ‰¾åˆ°å°æ‡‰çš„DICOMæª”æ¡ˆ: {dcm_path}")
            # é€™è£¡éœ€è¦å°‡DICOMè½‰ç‚ºåœ–åƒ
        else:
            print(f"\nâš ï¸ æ‰¾ä¸åˆ°åœ–åƒæª”æ¡ˆ: {image_path}")
    else:
        tester.visualize_model_output(image_path)
    
    # æ­¥é©Ÿ5: å¿«é€Ÿè¨“ç·´æ¸¬è©¦
    response = input("\næ˜¯å¦é€²è¡Œå¿«é€Ÿè¨“ç·´æ¸¬è©¦ï¼Ÿ(5 epochs) [y/n]: ")
    if response.lower() == 'y':
        tester.quick_training_test(annotations, num_epochs=5)
    
    # æ­¥é©Ÿ6: ç”Ÿæˆå ±å‘Š
    tester.generate_test_report(annotations)
    
    print("\n" + "="*60)
    print("âœ… æ¸¬è©¦å®Œæˆï¼")
    print("="*60)
    print("\nç”Ÿæˆçš„æª”æ¡ˆ:")
    print("  - test_output.png (æ¨¡å‹è¼¸å‡ºè¦–è¦ºåŒ–)")
    print("  - quick_training_loss.png (è¨“ç·´æå¤±æ›²ç·š)")
    print("  - test_report.json (æ¸¬è©¦å ±å‘Š)")
    print("\nä¸‹ä¸€æ­¥å»ºè­°:")
    print("  1. æª¢æŸ¥è¦–è¦ºåŒ–çµæœï¼Œç¢ºèªæ¨¡å‹æ¶æ§‹æ­£ç¢º")
    print("  2. å¦‚æœæå¤±ä¸‹é™ï¼Œå¯ä»¥é€²è¡Œå®Œæ•´è¨“ç·´")
    print("  3. æº–å‚™æ›´å¤šæ¨™è¨»æ•¸æ“šä»¥æå‡æ€§èƒ½")

if __name__ == "__main__":
    main()

#!/usr/bin/env python3
"""
è„Šæ¤çµ‚æ¿æª¢æ¸¬ - æ¨ç†è…³æœ¬
Spine Endplate Detection - Inference Script

ä½¿ç”¨è¨“ç·´å¥½çš„æ¨¡å‹é€²è¡Œæ¨ç†
"""

import os
import sys
import json
import argparse
import numpy as np
import cv2
import torch
import pydicom
import matplotlib.pyplot as plt
from pathlib import Path
from train_endplate_model import EndplateDetectionModel, get_transforms

class SpineAnalyzer:
    """è„Šæ¤åˆ†æå™¨"""
    
    def __init__(self, model_path, device='auto'):
        """
        åˆå§‹åŒ–åˆ†æå™¨
        
        Args:
            model_path: æ¨¡å‹æª”æ¡ˆè·¯å¾‘
            device: 'auto', 'cuda', æˆ– 'cpu'
        """
        # è¨­å‚™è¨­ç½®
        if device == 'auto':
            self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        else:
            self.device = torch.device(device)
        
        print(f"ğŸ”§ ä½¿ç”¨è¨­å‚™: {self.device}")
        
        # è¼‰å…¥æ¨¡å‹
        print(f"ğŸ“¦ è¼‰å…¥æ¨¡å‹: {model_path}")
        self.model = EndplateDetectionModel(pretrained=False)
        
        checkpoint = torch.load(model_path, map_location=self.device)
        self.model.load_state_dict(checkpoint['model_state_dict'])
        self.model = self.model.to(self.device)
        self.model.eval()
        
        # è¼‰å…¥é…ç½®
        self.config = checkpoint.get('config', {})
        print(f"âœ… æ¨¡å‹è¼‰å…¥å®Œæˆ")
        print(f"   è¨“ç·´epoch: {checkpoint.get('epoch', 'unknown')}")
        print(f"   é©—è­‰æå¤±: {checkpoint.get('val_loss', 'unknown'):.4f}" if 'val_loss' in checkpoint else "")
        
        # é è™•ç†
        self.transform = get_transforms(is_training=False)
    
    def load_image(self, image_path):
        """è¼‰å…¥å½±åƒï¼ˆæ”¯æ´DICOMå’Œä¸€èˆ¬å½±åƒæ ¼å¼ï¼‰"""
        image_path = str(image_path)
        
        if image_path.lower().endswith('.dcm'):
            # DICOMæª”æ¡ˆ
            dcm = pydicom.dcmread(image_path)
            image = dcm.pixel_array
            
            # è½‰æ›ç‚ºRGB
            if len(image.shape) == 2:
                image = np.stack([image] * 3, axis=-1)
            
            # æ­£è¦åŒ–åˆ°0-255
            image = ((image - image.min()) / (image.max() - image.min()) * 255).astype(np.uint8)
        else:
            # ä¸€èˆ¬å½±åƒæª”æ¡ˆ
            image = cv2.imread(image_path)
            if image is None:
                raise ValueError(f"ç„¡æ³•è®€å–å½±åƒ: {image_path}")
            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        
        return image
    
    def preprocess(self, image):
        """é è™•ç†å½±åƒ"""
        transformed = self.transform(image=image)
        input_tensor = transformed['image'].unsqueeze(0).to(self.device)
        return input_tensor
    
    def predict(self, image_path):
        """
        é æ¸¬çµ‚æ¿ä½ç½®
        
        Returns:
            dict: åŒ…å«é æ¸¬çµæœçš„å­—å…¸
        """
        # è¼‰å…¥å½±åƒ
        image = self.load_image(image_path)
        original_h, original_w = image.shape[:2]
        
        print(f"   åŸå§‹å½±åƒå°ºå¯¸: {original_w} Ã— {original_h}")
        
        # é è™•ç†
        input_tensor = self.preprocess(image)
        print(f"   æ¨¡å‹è¼¸å…¥å°ºå¯¸: {input_tensor.shape}")
        
        # æ¨ç†
        with torch.no_grad():
            predictions = self.model(input_tensor)
        
        # æå–çµæœ
        endplate_seg = predictions['endplate_seg'][0, 0].cpu().numpy()
        vertebra_edge_seg = predictions['vertebra_edge_seg'][0].cpu().numpy()
        keypoint_heatmap = predictions['keypoint_heatmap'][0, 0].cpu().numpy()
        
        print(f"   æ¨¡å‹è¼¸å‡ºå°ºå¯¸: {endplate_seg.shape}")
        
        # Resizeå›åŸå§‹å°ºå¯¸ï¼ˆç¢ºä¿ä½¿ç”¨æ­£ç¢ºçš„æ’å€¼æ–¹æ³•ï¼‰
        endplate_seg = cv2.resize(endplate_seg, (original_w, original_h), interpolation=cv2.INTER_LINEAR)
        anterior_edge = cv2.resize(vertebra_edge_seg[0], (original_w, original_h), interpolation=cv2.INTER_LINEAR)
        posterior_edge = cv2.resize(vertebra_edge_seg[1], (original_w, original_h), interpolation=cv2.INTER_LINEAR)
        keypoint_heatmap = cv2.resize(keypoint_heatmap, (original_w, original_h), interpolation=cv2.INTER_LINEAR)
        
        print(f"   Resizeå¾Œå°ºå¯¸: {endplate_seg.shape}")
        
        return {
            'image': image,
            'endplate_mask': endplate_seg,
            'anterior_edge': anterior_edge,
            'posterior_edge': posterior_edge,
            'keypoint_heatmap': keypoint_heatmap,
            'original_size': (original_w, original_h)  # ä¿å­˜åŸå§‹å°ºå¯¸
        }
    
    def extract_endplates(self, mask, threshold=0.5, min_length=30):
        """å¾é®ç½©æå–çµ‚æ¿ç·šæ®µ"""
        print(f"   æå–çµ‚æ¿ - é®ç½©å°ºå¯¸: {mask.shape}, é–¾å€¼: {threshold}")
        
        binary_mask = (mask > threshold).astype(np.uint8) * 255
        
        # æª¢æŸ¥æœ‰æ•ˆåƒç´ 
        valid_pixels = np.sum(binary_mask > 0)
        print(f"   äºŒå€¼åŒ–é®ç½© - æœ‰æ•ˆåƒç´ æ•¸: {valid_pixels}")
        
        # éœå¤«ç·šæ®µæª¢æ¸¬
        lines = cv2.HoughLinesP(
            binary_mask,
            rho=1,
            theta=np.pi/180,
            threshold=50,
            minLineLength=min_length,
            maxLineGap=10
        )
        
        if lines is None:
            print(f"   âš ï¸ æœªæª¢æ¸¬åˆ°ç·šæ®µ")
            return []
        
        print(f"   åˆæ­¥æª¢æ¸¬åˆ° {len(lines)} æ¢ç·šæ®µ")
        
        # åˆä½µç›¸è¿‘çš„ç·šæ®µ
        merged_lines = self._merge_lines(lines)
        print(f"   åˆä½µå¾Œå‰©é¤˜ {len(merged_lines)} æ¢ç·šæ®µ")
        
        # æŒ‰yåº§æ¨™æ’åºï¼ˆå¾ä¸Šåˆ°ä¸‹ï¼‰
        merged_lines = sorted(merged_lines, key=lambda l: (l[1] + l[3]) / 2)
        
        # è¼¸å‡ºç·šæ®µåº§æ¨™ç¯„åœä¾›èª¿è©¦
        if merged_lines:
            x_coords = [x for line in merged_lines for x in [line[0], line[2]]]
            y_coords = [y for line in merged_lines for y in [line[1], line[3]]]
            print(f"   ç·šæ®µåº§æ¨™ç¯„åœ: X[{min(x_coords)}-{max(x_coords)}], Y[{min(y_coords)}-{max(y_coords)}]")
        
        return merged_lines
    
    def _merge_lines(self, lines, angle_threshold=10, distance_threshold=20):
        """åˆä½µç›¸è¿‘çš„ç·šæ®µ"""
        if len(lines) == 0:
            return []
        
        merged = []
        lines = [line[0] for line in lines]
        
        while lines:
            line1 = lines.pop(0)
            x1, y1, x2, y2 = line1
            angle1 = np.arctan2(y2 - y1, x2 - x1) * 180 / np.pi
            
            # æ‰¾åˆ°ç›¸ä¼¼çš„ç·šæ®µ
            similar = [line1]
            i = 0
            while i < len(lines):
                x3, y3, x4, y4 = lines[i]
                angle2 = np.arctan2(y4 - y3, x4 - x3) * 180 / np.pi
                
                # æª¢æŸ¥è§’åº¦å’Œè·é›¢
                if abs(angle1 - angle2) < angle_threshold:
                    dist = min(
                        np.sqrt((x1-x3)**2 + (y1-y3)**2),
                        np.sqrt((x2-x4)**2 + (y2-y4)**2)
                    )
                    if dist < distance_threshold:
                        similar.append(lines.pop(i))
                        continue
                i += 1
            
            # åˆä½µç‚ºä¸€æ¢ç·šæ®µ
            if similar:
                all_points = np.array([(x1, y1, x2, y2) for x1, y1, x2, y2 in similar])
                x_min, x_max = all_points[:, [0, 2]].min(), all_points[:, [0, 2]].max()
                y_mean1 = all_points[:, 1].mean()
                y_mean2 = all_points[:, 3].mean()
                merged.append([int(x_min), int(y_mean1), int(x_max), int(y_mean2)])
        
        return merged
    
    def calculate_angles(self, endplate_lines):
        """è¨ˆç®—æ¤é–“éš™è§’åº¦"""
        angles = []
        
        for i in range(len(endplate_lines) - 1):
            line1 = endplate_lines[i]
            line2 = endplate_lines[i + 1]
            
            x1, y1, x2, y2 = line1
            x3, y3, x4, y4 = line2
            
            angle1 = np.arctan2(y2 - y1, x2 - x1) * 180 / np.pi
            angle2 = np.arctan2(y4 - y3, x4 - x3) * 180 / np.pi
            
            angle_diff = abs(angle1 - angle2)
            if angle_diff > 90:
                angle_diff = 180 - angle_diff
            
            angles.append({
                'level': i + 1,
                'angle': round(angle_diff, 1),
                'lower_line': line1,
                'upper_line': line2
            })
        
        return angles
    
    def visualize(self, results, output_path=None, show=True):
        """è¦–è¦ºåŒ–çµæœ"""
        image = results['image']
        endplate_mask = results['endplate_mask']
        anterior_edge = results['anterior_edge']
        posterior_edge = results['posterior_edge']
        keypoint_heatmap = results['keypoint_heatmap']
        
        # æå–çµ‚æ¿ç·šæ®µ
        endplate_lines = self.extract_endplates(endplate_mask)
        
        # è¨ˆç®—è§’åº¦
        angles = self.calculate_angles(endplate_lines) if len(endplate_lines) >= 2 else []
        
        # å‰µå»ºè¦–è¦ºåŒ–
        fig, axes = plt.subplots(2, 3, figsize=(18, 12))
        fig.suptitle('è„Šæ¤çµ‚æ¿æª¢æ¸¬çµæœ', fontsize=16, fontweight='bold')
        
        # åŸå§‹å½±åƒ
        axes[0, 0].imshow(image)
        axes[0, 0].set_title('åŸå§‹å½±åƒ')
        axes[0, 0].axis('off')
        
        # çµ‚æ¿æª¢æ¸¬
        axes[0, 1].imshow(image)
        axes[0, 1].imshow(endplate_mask, alpha=0.5, cmap='Reds')
        axes[0, 1].set_title(f'çµ‚æ¿æª¢æ¸¬ ({len(endplate_lines)} æ¢ç·šæ®µ)')
        axes[0, 1].axis('off')
        
        # å‰ç·£æª¢æ¸¬
        axes[0, 2].imshow(image)
        axes[0, 2].imshow(anterior_edge, alpha=0.5, cmap='Blues')
        axes[0, 2].set_title('æ¤é«”å‰ç·£')
        axes[0, 2].axis('off')
        
        # å¾Œç·£æª¢æ¸¬
        axes[1, 0].imshow(image)
        axes[1, 0].imshow(posterior_edge, alpha=0.5, cmap='Oranges')
        axes[1, 0].set_title('æ¤é«”å¾Œç·£')
        axes[1, 0].axis('off')
        
        # é—œéµé»
        axes[1, 1].imshow(image)
        axes[1, 1].imshow(keypoint_heatmap, alpha=0.5, cmap='hot')
        axes[1, 1].set_title('é—œéµé»æª¢æ¸¬')
        axes[1, 1].axis('off')
        
        # æœ€çµ‚çµæœï¼ˆç¹ªè£½ç·šæ®µå’Œè§’åº¦ï¼‰
        result_img = image.copy()
        for i, line in enumerate(endplate_lines):
            x1, y1, x2, y2 = line
            cv2.line(result_img, (x1, y1), (x2, y2), (255, 0, 0), 3)
            
            # æ¨™è¨˜æ¤é–“éš™å’Œè§’åº¦
            if i < len(angles):
                angle_info = angles[i]
                mid_y = (y1 + y2) // 2
                cv2.putText(result_img, f"#{angle_info['level']}: {angle_info['angle']}Â°",
                           (10, mid_y), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
        
        axes[1, 2].imshow(result_img)
        axes[1, 2].set_title(f'æœ€çµ‚çµæœ ({len(angles)} å€‹è§’åº¦)')
        axes[1, 2].axis('off')
        
        plt.tight_layout()
        
        if output_path:
            plt.savefig(output_path, dpi=150, bbox_inches='tight')
            print(f"âœ… è¦–è¦ºåŒ–çµæœå·²å„²å­˜: {output_path}")
        
        if show:
            plt.show()
        
        return angles, endplate_lines
    
    def analyze(self, image_path, output_dir=None, visualize=True):
        """å®Œæ•´åˆ†ææµç¨‹"""
        print(f"\nğŸ“¸ åˆ†æå½±åƒ: {image_path}")
        
        # é æ¸¬
        results = self.predict(image_path)
        
        # æå–çµ‚æ¿
        endplate_lines = self.extract_endplates(results['endplate_mask'])
        print(f"   æª¢æ¸¬åˆ° {len(endplate_lines)} æ¢çµ‚æ¿ç·šæ®µ")
        
        # è¨ˆç®—è§’åº¦
        angles = self.calculate_angles(endplate_lines)
        print(f"   è¨ˆç®—å‡º {len(angles)} å€‹æ¤é–“éš™è§’åº¦")
        
        for angle_info in angles:
            print(f"   - æ¤é–“éš™ #{angle_info['level']}: {angle_info['angle']}Â°")
        
        # è¦–è¦ºåŒ–
        if visualize and output_dir:
            output_path = Path(output_dir) / f"{Path(image_path).stem}_result.png"
            self.visualize(results, output_path=output_path, show=False)
        elif visualize:
            self.visualize(results, show=True)
        
        # æº–å‚™è¼¸å‡º
        output = {
            'image_file': str(image_path),
            'num_endplates': len(endplate_lines),
            'num_angles': len(angles),
            'endplate_lines': [
                {'x1': int(l[0]), 'y1': int(l[1]), 'x2': int(l[2]), 'y2': int(l[3])}
                for l in endplate_lines
            ],
            'angles': angles
        }
        
        # å„²å­˜JSON
        if output_dir:
            json_path = Path(output_dir) / f"{Path(image_path).stem}_result.json"
            with open(json_path, 'w', encoding='utf-8') as f:
                json.dump(output, f, indent=2, ensure_ascii=False)
            print(f"âœ… JSONçµæœå·²å„²å­˜: {json_path}")
        
        return output

def main():
    parser = argparse.ArgumentParser(description='è„Šæ¤çµ‚æ¿æª¢æ¸¬æ¨ç†')
    parser.add_argument('--model', type=str, default='best_endplate_model.pth',
                       help='æ¨¡å‹æª”æ¡ˆè·¯å¾‘')
    parser.add_argument('--input', type=str, required=True,
                       help='è¼¸å…¥å½±åƒæˆ–è³‡æ–™å¤¾è·¯å¾‘')
    parser.add_argument('--output', type=str, default='inference_results',
                       help='è¼¸å‡ºçµæœè³‡æ–™å¤¾')
    parser.add_argument('--device', type=str, default='auto',
                       choices=['auto', 'cuda', 'cpu'],
                       help='è¨ˆç®—è¨­å‚™')
    parser.add_argument('--no-viz', action='store_true',
                       help='ä¸ç”Ÿæˆè¦–è¦ºåŒ–çµæœ')
    
    args = parser.parse_args()
    
    # å‰µå»ºè¼¸å‡ºç›®éŒ„
    output_dir = Path(args.output)
    output_dir.mkdir(exist_ok=True, parents=True)
    
    # åˆå§‹åŒ–åˆ†æå™¨
    analyzer = SpineAnalyzer(args.model, device=args.device)
    
    # è™•ç†è¼¸å…¥
    input_path = Path(args.input)
    
    if input_path.is_file():
        # å–®ä¸€æª”æ¡ˆ
        analyzer.analyze(
            input_path,
            output_dir=output_dir,
            visualize=not args.no_viz
        )
    elif input_path.is_dir():
        # è³‡æ–™å¤¾ï¼ˆæ‰¹æ¬¡è™•ç†ï¼‰
        image_files = list(input_path.glob('*.dcm')) + \
                     list(input_path.glob('*.png')) + \
                     list(input_path.glob('*.jpg'))
        
        print(f"\nğŸ“ æ‰¹æ¬¡è™•ç†: {len(image_files)} å€‹æª”æ¡ˆ")
        
        for img_file in image_files:
            try:
                analyzer.analyze(
                    img_file,
                    output_dir=output_dir,
                    visualize=not args.no_viz
                )
            except Exception as e:
                print(f"âŒ è™•ç†å¤±æ•— {img_file}: {e}")
                continue
        
        print(f"\nâœ… æ‰¹æ¬¡è™•ç†å®Œæˆï¼çµæœå„²å­˜åœ¨: {output_dir}")
    else:
        print(f"âŒ è¼¸å…¥è·¯å¾‘ç„¡æ•ˆ: {args.input}")
        return 1
    
    return 0

if __name__ == "__main__":
    sys.exit(main())

